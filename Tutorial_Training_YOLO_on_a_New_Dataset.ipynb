{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3RoffwKbNwSOXqcwto9ab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyankkalgaonkar/yolo-custom-dataset-training-tutorial/blob/main/Tutorial_Training_YOLO_on_a_New_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 0 — Upload kaggle.json\n",
        "\n",
        "Go to https://www.kaggle.com\n",
        " → Account → API → Create New API Token\n",
        "\n",
        "A file named kaggle.json will download.\n",
        "\n",
        "In Colab, run the first cell below and upload it."
      ],
      "metadata": {
        "id": "3nDdXlKXy7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## STEP 1 — Install Kaggle + ultralytics (YOLO)\n",
        "\n",
        "# Install the Kaggle API package to download datasets from Kaggle\n",
        "# The -q flag makes the installation quiet (less output)\n",
        "!pip install kaggle -q\n",
        "\n",
        "# Install the ultralytics package which contains YOLO (You Only Look Once)\n",
        "!pip install ultralytics -q\n",
        "\n",
        "\n",
        "\n",
        "## STEP 2 — Upload kaggle.json (API credentials)\n",
        "\n",
        "# This will open a file upload dialog - upload your kaggle.json here\n",
        "# kaggle.json contains your API credentials for accessing Kaggle datasets\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload kaggle.json here\n",
        "\n",
        "# Import operating system and JSON modules for file and directory operations\n",
        "import os, json\n",
        "\n",
        "# Create the .kaggle directory in the root folder if it doesn't exist\n",
        "# This is where Kaggle expects to find its configuration file\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Move the uploaded kaggle.json file to the correct location\n",
        "# The for loop handles the uploaded files, in our case, just the kaggle.json\n",
        "for fn in uploaded:\n",
        "    os.rename(fn, '/root/.kaggle/kaggle.json')\n",
        "\n",
        "# Change file permissions to read/write for owner only (600)\n",
        "# This is a security requirement for the Kaggle API\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API is ready.\")"
      ],
      "metadata": {
        "id": "fcRlWDvcn48s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## STEP 3 — Download dataset from Kaggle\n",
        "\n",
        "# Download your head detection CCTV dataset from Kaggle\n",
        "# The -d flag specifies the dataset to download\n",
        "!kaggle datasets download -d hoangxuanviet/head-detection-cctv\n",
        "\n",
        "# Unzip the downloaded dataset into a folder called 'dataset'\n",
        "# The -d flag specifies the destination directory\n",
        "# This will create a dataset folder with train, test, and validation splits\n",
        "!unzip head-detection-cctv.zip -d dataset"
      ],
      "metadata": {
        "id": "wcrSrhqUoQVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List dataset folder\n",
        "!ls dataset\n",
        "# See whats inside this folder"
      ],
      "metadata": {
        "id": "-WCDxP2_oV18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile head_dataset.yaml\n",
        "\n",
        "# This creates a YAML configuration file for the YOLO dataset\n",
        "# YAML files are used to configure training parameters and dataset paths\n",
        "\n",
        "# Path to the training images\n",
        "# YOLO will look in this directory for training images\n",
        "train: dataset/train/images\n",
        "\n",
        "# Path to the validation images\n",
        "# YOLO will use these images to validate model performance during training\n",
        "val: dataset/val/images\n",
        "\n",
        "# Number of classes (nc) in the dataset\n",
        "# Since we're only detecting heads, we have 1 class\n",
        "nc: 1\n",
        "\n",
        "# Class names (names) - the labels for our classes\n",
        "# We only have one class called \"head\"\n",
        "# The order matters - index 0 corresponds to \"head\"\n",
        "names: [\"head\"]"
      ],
      "metadata": {
        "id": "9AjBEXT7ogRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we run into issue where the dataset creates a folder named 'valid' but YOLO expects 'val' folder name. There's a mistmatch. so we rename the folder.\n",
        "\n",
        "import os\n",
        "\n",
        "os.rename(\"dataset/valid\", \"dataset/val\")"
      ],
      "metadata": {
        "id": "DQ4IoQfGpDVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to confirm if the folder was renamed correctly, we cross-check:\n",
        "!ls dataset"
      ],
      "metadata": {
        "id": "9QMpS_rmotXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we'll run this example training to confirm that YOLO is training on our dataset.\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 small model\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    data=\"head_dataset.yaml\",\n",
        "    imgsz=640,\n",
        "    epochs=50,\n",
        "    batch=16,\n",
        "    workers=2,\n",
        ")\n"
      ],
      "metadata": {
        "id": "725ZSRhRonBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tutorial created by Prof. Kalgaonkar at Lafayette College."
      ],
      "metadata": {
        "id": "hJQvehGC3-DV"
      }
    }
  ]
}